<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>梨串桃的生活日记</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2026-01-04T12:02:30.442Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>ChuantaoLi</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>《Optimal Discriminant Support Vector Machine》阅读笔记</title>
    <link href="http://example.com/2026/01/04/Optimal-Discriminant-Support-Vector-Machine%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <id>http://example.com/2026/01/04/Optimal-Discriminant-Support-Vector-Machine%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</id>
    <published>2026-01-04T11:58:29.000Z</published>
    <updated>2026-01-04T12:02:30.442Z</updated>
    
    <content type="html"><![CDATA[<h1 id="模型总览">模型总览</h1><p>ODSVM 将子空间学习和 SVM 分类放在一个统一的数学框架内共同进化。</p><h2 id="投影矩阵数据的特征提取器">投影矩阵：数据的特征提取器</h2><p><span class="math inline">\(P\)</span> 是一个大小为 <spanclass="math inline">\(d \times m\)</span> 的矩阵（<spanclass="math inline">\(d\)</span> 是原始高维特征维度，<spanclass="math inline">\(m\)</span> 是降维后的维度）。它的作用是将原始样本<span class="math inline">\(x_i\)</span> 投影到低维子空间： <spanclass="math display">\[z_i = P^\top x_i\]</span> <span class="math inline">\(P\)</span>的目标在于丢弃大部分冗余信息的同时，精准地保留最有利于分类的信息。在ODSVM 中，<span class="math inline">\(P\)</span> 的构建受到 SVM边距最大化的约束。这意味着 <span class="math inline">\(P\)</span>提取出的特征 <span class="math inline">\(z_i\)</span> 必须让 SVM能够更容易地找到一个宽阔的分类间隔（Margin）。</p><h2 id="重构矩阵数据的结构保持器">重构矩阵：数据的结构保持器</h2><p><span class="math inline">\(Q\)</span> 同样是一个 <spanclass="math inline">\(d \times m\)</span>的矩阵，用于衡量投影后的低维特征 <spanclass="math inline">\(z_i\)</span> 是否还保留了原始数据 <spanclass="math inline">\(x_i\)</span>的核心结构。数学上表现为最小化重构误差：<spanclass="math inline">\(\|x_i - Qz_i\|^2\)</span>。如果只追求分类准确率（只优化 <span class="math inline">\(P\)</span> 和SVM 参数），模型可能会陷入过拟合，或者提取出极其扭曲的特征。<spanclass="math inline">\(Q\)</span> 的存在就像是一条绳子，拉住 <spanclass="math inline">\(P\)</span>，要求提取的特征不仅要能分得开类别，还得能代表原本的数据。</p><h2 id="迭代优化">迭代优化</h2><p>在 ODSVM 的目标函数中，SVM 的参数（<span class="math inline">\(w,b\)</span>）、投影矩阵 <span class="math inline">\(P\)</span> 和重构矩阵<span class="math inline">\(Q\)</span>是紧密耦合在一起的。由于无法直接求出所有变量的最优解，因此论文采用交替迭代优化（AlternatingOptimization）的策略。</p><ol type="1"><li><p>第一步：固定 <span class="math inline">\(P\)</span> 和 <spanclass="math inline">\(Q\)</span>，优化 SVM，找最强判别平面</p><p>此时，<span class="math inline">\(P\)</span> 已经把数据变成了低维特征<span class="math inline">\(z_i\)</span>。模型退化成一个标准的 SVM问题。当前的子空间里，找到能把不同类别分得最开的超平面 <spanclass="math inline">\((w, b)\)</span>。</p></li><li><p>第二步：固定 SVM 参数和 <spanclass="math inline">\(Q\)</span>，优化 <spanclass="math inline">\(P\)</span></p><p><span class="math inline">\(P\)</span> 需要同时满足两个要求：SVM要求投影 <span class="math inline">\(z_i\)</span>得让它的分类间隔更大，<span class="math inline">\(Q\)</span> 要求投影<span class="math inline">\(z_i\)</span> 要能配合重构矩阵更好地还原回<span class="math inline">\(x_i\)</span>。在这种约束下，<spanclass="math inline">\(P\)</span>会被微调，使得投影后的数据点在保持结构的同时，向着更有利于分类的方向偏移。</p></li><li><p>第三步：固定 <span class="math inline">\(P\)</span> 和 SVM，优化<span class="math inline">\(Q\)</span></p><p>由于 <span class="math inline">\(P\)</span> 已经变了，原来的恢复方案<span class="math inline">\(Q\)</span> 可能不再准确。这一步更新 <spanclass="math inline">\(Q\)</span>，使得它能根据新的低维特征 <spanclass="math inline">\(z_i\)</span> 更好地重建原始数据。</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;模型总览&quot;&gt;模型总览&lt;/h1&gt;
&lt;p&gt;ODSVM 将子空间学习和 SVM 分类放在一个统一的数学框架内共同进化。&lt;/p&gt;
&lt;h2 id=&quot;投影矩阵数据的特征提取器&quot;&gt;投影矩阵：数据的特征提取器&lt;/h2&gt;
&lt;p&gt;&lt;span class=&quot;math inline</summary>
      
    
    
    
    <category term="集成学习" scheme="http://example.com/categories/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="子空间学习" scheme="http://example.com/tags/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
</feed>
