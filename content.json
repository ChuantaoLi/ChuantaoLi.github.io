{"meta":{"title":"梨串桃的生活日记","subtitle":"","description":"感知幸福是一种能力","author":"ChuantaoLi","url":"http://example.com","root":"/"},"pages":[{"title":"我的简介","date":"2024-04-10T15:41:56.000Z","updated":"2026-01-04T08:45:07.597Z","comments":false,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":""},{"title":"标签","date":"2024-04-10T15:41:25.000Z","updated":"2026-01-04T08:43:35.421Z","comments":false,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"","date":"2026-01-04T08:20:20.272Z","updated":"2026-01-04T08:20:20.272Z","comments":true,"path":"speak/index.html","permalink":"http://example.com/speak/index.html","excerpt":"","text":"#bber { margin-top: 20px; } .bb-list-item { background: #fff; border-radius: 12px; padding: 15px; margin-bottom: 20px; box-shadow: 0 4px 6px rgba(0,0,0,0.05); border: 1px solid #eee; } .bb-content { font-size: 15px; color: #333; line-height: 1.6; } .bb-datetime { font-size: 12px; color: #999; margin-top: 8px; } var bbMemos = { memos : 'https://lct-memos.pages.dev/',//修改为自己部署 Memos 的网址，末尾有 / 斜杠 limit : '',//默认每次显示 10 条 creatorId:'1' ,//早期默认为 101 用户，新安装是 1； https://demo.usememos.com/u/101 domId: '#bber',//默认为 bber twiEnv:'',//启开 twikoo 评论，默认 https://metk.edui.fun/ }"},{"title":"生活记录","date":"2026-01-04T17:16:55.266Z","updated":"2026-01-04T17:16:55.266Z","comments":true,"path":"memos/index.html","permalink":"http://example.com/memos/index.html","excerpt":"","text":"#bber { margin-top: 20px; font-family: 'LXGW WenKai Screen', sans-serif; } .bb-list-item { background: rgba(255, 255, 255, 0.85); border-radius: 20px; padding: 25px; margin-bottom: 24px; box-shadow: 0 10px 30px rgba(0, 0, 0, 0.08); transition: transform 0.3s ease; } .bb-list-item:hover { transform: translateY(-5px); } .bb-content { font-size: 15px; color: #333; line-height: 1.6; } .bb-datetime { font-size: 12px; color: #999; margin-top: 12px; border-top: 1px dashed #eee; padding-top: 8px; } /* --- 图片展示优化设计 --- */ .bb-content img { cursor: zoom-in; /* 鼠标移动上去显示放大镜图标 */ max-width: 400px; /* 限制图片最大宽度，不至于撑满屏幕 */ max-height: 300px; /* 限制高度，防止长图过长 */ object-fit: cover; /* 保持图片比例缩放 */ border-radius: 12px; margin: 10px 0; display: block; box-shadow: 0 4px 12px rgba(0,0,0,0.1); transition: opacity 0.3s ease; } .bb-content img:hover { opacity: 0.8; } /* 鼠标悬停略微变暗提示可点击 */ /* 适配手机端：图片自动充满宽度 */ @media screen and (max-width: 768px) { .bb-content img { max-width: 100%; max-height: 400px; } } 正在加载备忘录... var bbMemos = { memos: 'https://memos-api.lct-memos.workers.dev/', limit: '10', creatorId: '1', domId: '#bber', } async function loadMemos() { const bber &#x3D; document.querySelector(bbMemos.domId); &#x2F;&#x2F; 适配 Memos v1 API 路径（如果加载不出，尝试去掉末尾的 s） const fetchUrl &#x3D; ${bbMemos.memos}api/v1/memo?creatorId=${bbMemos.creatorId}&amp;limit=${bbMemos.limit}&amp;rowStatus=NORMAL; try { const res &#x3D; await fetch(fetchUrl); const memos &#x3D; await res.json(); let html &#x3D; “”; memos.forEach(memo &#x3D;&gt; { let content &#x3D; marked.parse(memo.content); let date &#x3D; new Date(memo.createdTs * 1000).toLocaleString(); html +&#x3D; &lt;div class=&quot;bb-list-item&quot;&gt; &lt;div class=&quot;bb-content&quot;&gt;${content}&lt;/div&gt; &lt;div class=&quot;bb-datetime&quot;&gt;${date}&lt;/div&gt; &lt;/div&gt;; }); bber.innerHTML &#x3D; html; // 初始化图片点击放大功能 window.ViewImage &amp;&amp; ViewImage.init(&#39;.bb-content img&#39;); } catch (err) { bber.innerHTML = &quot;加载失败，请检查后端设置。&quot;; } } window.addEventListener(‘DOMContentLoaded’, loadMemos);"},{"title":"博客类型","date":"2024-04-10T15:40:31.000Z","updated":"2026-01-04T08:39:50.086Z","comments":false,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"PyTorch学习笔记","slug":"PyTorch学习笔记","date":"2026-01-13T13:51:19.000Z","updated":"2026-01-13T13:53:09.371Z","comments":true,"path":"2026/01/13/PyTorch学习笔记/","permalink":"http://example.com/2026/01/13/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"本文记录了我对PyTorch的学习过程，参考B站小土堆课程。","text":"本文记录了我对PyTorch的学习过程，参考B站小土堆课程。 PyTorch学习笔记数据读取使用Dataset进行数据读取在PyTorch中，Dataset是一个抽象基类，其规定了所有数据集必须具备两个功能： __len__：告诉模型这里一共有多少张图 __getitem__：告诉模型一个编号idx，把对应的图片和标签给你 __getitem__ 的按需读取并没有在init中把所有图片都加载进内存，只有当代码运行到dataset[idx]时，Image.open才会去磁盘读取这一张图。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import osfrom PIL import Imagefrom torch.utils.data import Dataset # 导入Dataset基类\"\"\"定义一个名为MyData的类，继承PyTorch提供的Dataset类\"\"\"class MyDataSet(Dataset): # 初始化方法：用于获取数据的信息 def __init__(self, root_dirt, label_dirt): \"\"\" :param root_dirt: 数据集的根目录路径 :param label_dirt: 标签的文件夹名称 \"\"\" self.root_dirt = root_dirt self.label_dirt = label_dirt # 使用os.path.join拼接路径 self.path = os.path.join(self.root_dirt, self.label_dirt) # 获取该目录下所有文件的文件名，以列表的形式存储 self.img_path = os.listdir(self.path) # 获取单个数据样本的方法 def __getitem__(self, idx): \"\"\" :param idx: 数据的编号，如第0张图，第1张图 :return: 返回处理后的图像和对应的标签 \"\"\" # 1. 根据索引idx从文件夹列表中获取对应的文件名 img_name = self.img_path[idx] # 2. 拼接出完整路径 img_item_path = os.path.join(self.root_dirt, self.label_dirt, img_name) # 3. 使用PIL库的open打开图片文件 img = Image.open(img_item_path) # 4. 获取标签，使用文件夹名称作为标签名称 label = self.label_dirt # 5. 返回一个元组：（图片，标签） return img, label # 获取数据集样本的长度 def __len__(self): return len(self.img_path)\"\"\"代码测试\"\"\"# 1. 设置数据集所在的绝对路径root_dirt = r\"D:\\RecommendationSystem\\PyTorch学习\\hymenoptera_data\\train\"ants_label_dir = \"ants\" # 蚂蚁文件夹bees_label_dir = \"bees\" # 蜜蜂文件夹# 2. 创建蚂蚁数据集的实例对象ants_dataset = MyDataSet(root_dirt, ants_label_dir)# 3. 访问数据集，通过索引触发__getitem__方法img, label = ants_dataset[0]img.show() 使用DataLoader进行批量读取DataLoader用于批量读取，在神经网络中常常输入一个batch进行训练。常见的参数有Batch Size，表示批次大小；Shuffle，表示输入前对样本顺序进行洗牌。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455from torch.utils.data import DataLoaderfrom torch.utils.data import Datasetfrom torchvision import transformsfrom PIL import Imageimport osclass MyData(Dataset): def __init__(self, root_dir, label_dir, transforms=None): self.root_dir = root_dir self.label_dir = label_dir self.path = os.path.join(self.root_dir, self.label_dir) self.img_path = os.listdir(self.path) # 用os的listdir获取数据集的图片列表 self.transform = transforms # 输入图像转换操作 def __getitem__(self, idx): img_name = self.img_path[idx] # 根据idx获取单张图片 img_item_path = os.path.join(self.root_dir, self.label_dir, img_name) img = Image.open(img_item_path).convert(\"RGB\") # 强制转换成三通道 if self.transform: img = self.transform(img) label = self.label_dir return img, label def __len__(self): return len(self.img_path)# 定义一个变换，因为DataLoader的输入是张量img_transforms = transforms.Compose( [ transforms.Resize((256, 256)), # 进行缩放 transforms.RandomHorizontalFlip(), # 随机水平翻转，数据增强, transforms.ToTensor(), # 转换为张量 transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.1, 0.1, 0.1]), # 标准化 ])# 创建蚂蚁数据集实例root_dir = r\"D:\\RecommendationSystem\\PyTorch学习\\hymenoptera_data\\train\" # 根目录，存储数据级的目录ants_label_dir = \"ants\" # 蚂蚁类别的数据集目录bees_label_dir = \"bees\" # 蜜蜂类别的数据集目录ants_dataset = MyData(root_dir, ants_label_dir, transforms=img_transforms)MyDataLoader = DataLoader( dataset=ants_dataset, batch_size=32, shuffle=True, drop_last=False)for data in MyDataLoader: imgs, labels = data print(f\"当前批次的图片形状：{imgs.shape}\") 使用Transforms进行数据转换12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273from PIL import Imagefrom torchvision import transformsimport matplotlib.pyplot as plt# 1. 加载图片img = Image.open(r\"C:\\Users\\13680\\Pictures\\猫咪头像.jpg\")# 2. 从图片到张量 (ToTensor)# 目的：将 PIL 图片转为模型能处理的浮点张量，并将像素范围从 [0, 255] 归一化到 [0, 1]# 还会自动把维度顺序从 [H, W, C] 调整为 [C, H, W]to_tensor = transforms.ToTensor()img_tensor = to_tensor(img)print(f\"张量形状 [通道, 高, 宽]: {img_tensor.shape}\")# 3. 尺寸缩放 (Resize)# 目的：统一输入尺寸。模型网络层的参数是固定的，必须接受相同大小的图片resize = transforms.Resize((512, 512))img_resized = resize(img)print(f\"缩放后形状: {to_tensor(img_resized).shape}\")# 4. 中心裁剪 (CenterCrop)# 目的：移除背景干扰，只关注图片最中心的核心特征，比如猫脸centercrop = transforms.CenterCrop(300)img_croped = centercrop(img)# 5. 随机裁剪 (RandomCrop)randomcrop = transforms.RandomCrop(size=(100, 200))img_randomcroped = randomcrop(img)# 6. 随机水平翻转 (RandomHorizontalFlip)# 目的：模拟物体从不同方向出现的情况。p=0.5 表示一半的概率翻转，一半不翻random_horizontal_flip = transforms.RandomHorizontalFlip(p=0.5)flipped_image = random_horizontal_flip(img)# 绘图展示对比plt.figure(figsize=(10, 5))plt.subplot(1, 2, 1)plt.title(\"Original Image\")plt.imshow(img)plt.axis(\"off\") # 关闭坐标轴plt.subplot(1, 2, 2)plt.title(\"Flipped Image\")plt.imshow(flipped_image)plt.axis(\"off\")# plt.show()# 7. 填充 (Pad)# 目的：给图片加边框。在某些检测任务中，为了保持比例会先填充再缩放pad = transforms.Pad(padding=10, fill=0) # 上下左右各填充 10 像素，黑色填充img_padded = pad(img)print(f\"填充后形状: {to_tensor(img_padded).shape}\")# 8. 标准化 (Normalize)# 公式：output = (input - mean) / std# 目的：使数据分布在 0 附近。均值 0.5，标准差 0.1 是为了让大多数像素落在 [-5, 5] 之间mean = [0.5, 0.5, 0.5]std = [0.1, 0.1, 0.1]normalize = transforms.Normalize(mean=mean, std=std)img_normalized = normalize(to_tensor(img))print(f\"标准化后的像素均值: {img_normalized.mean()}\")# 9. 操作组合 (Compose)# 目的：将上述所有步骤串联成一个流水线，以后只需调用 img_transforms(img)img_transforms = transforms.Compose( [ transforms.Resize((256, 256)), # 1. 缩放 transforms.RandomHorizontalFlip(), # 2. 增强 transforms.ToTensor(), # 3. 转张量 transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.1, 0.1, 0.1]), # 4. 标准化 ])img_transformed = img_transforms(img) 神经网络Module的使用输出通道 （Out Channels）其实就是卷积核（Filter）的数量。每一个卷积核负责寻找一种特征。设置64个输出通道，就代表想让模型在这一层提取64种不同的高级特征。 当kernel_size=3，padding=1，stride=1时，卷积后的图片长宽不变，公式如下：这让我们在设计网络时，只需要担心“池化”带来的减半，而不需要担心卷积层让图片变小。 如果没有激活函数F.relu，无论你堆叠多少层卷积，结果依然只是一个复杂的线性公式。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import torchimport torch.nn as nnimport torch.nn.functional as Fclass Mymodel(nn.Module): def __init__(self, num_classes): super().__init__() # 1. 卷积层 self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1) self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1) self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1) \"\"\" 输入通道数，输出通道数，填充大小 后一层的输入通道数要等于前一层的输出通道数 padding = (kernel_size - 1) / 2 \"\"\" # 2. 池化层 self.pool = nn.MaxPool2d(kernel_size=2, stride=2) \"\"\" kernel_size是窗口大小，stride是窗口每次滑动的距离，二者相等时，池化后的图像大小减半 \"\"\" # 3. 全连接层 self.fc1 = nn.Linear(64 * 64 * 64, 256) # 假设输入图像的形状：(3, 512, 512) self.fc2 = nn.Linear(256, num_classes) def forward(self, x): # 卷积 -&gt; 激活 -&gt; 池化 x = self.pool( F.relu(self.conv1(x)) ) # 卷积后：(16, 512, 512)；池化后：(16, 256, 256) x = self.pool( F.relu(self.conv2(x)) ) # 卷积后：(32, 256, 256)；池化后：(32, 128, 128) x = self.pool( F.relu(self.conv3(x)) ) # 卷积后：(64, 128, 128)；池化后：(64, 64, 64) # 展平，进入全连接层前，需要把多维张量拉成一维向量 x = torch.flatten(x, 1) x = F.relu(self.fc1(x)) x = self.fc2(x) return xmodel = Mymodel(num_classes=2)print(model) 池化的使用最大池化只看最强的信号，它能很好地提取边缘、纹理等剧烈变化的特征。平均池化 考虑所有像素，常用于网络的最后一层，用来整合全局信息。 一个非常普遍的工程习惯是kernel_size == stride。如果kernel_size=2，stride=2，图片尺寸直接除以2。如果stride小于kernel_size，池化窗口会产生重叠，这在如AlexNet等某些老模型中被认为能抑制过拟合。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import torchimport torch.nn as nn# 模拟一个 4x4 的输入特征图 (Batch=1, Channel=1, H=4, W=4)input_data = torch.tensor( [[[[10, 20, 5, 0], [30, 40, 0, 5], [1, 2, 100, 80], [0, 1, 90, 70]]]], dtype=torch.float32,)# 1. 最大池化 (Max Pooling)# 目的：保留窗口内最显著的特征（数值最大的那个）# 窗口 2x2，步长 2：意味着图片长宽都会减半max_pool = nn.MaxPool2d(kernel_size=2, stride=2)# 2. 平均池化 (Average Pooling)# 目的：保留窗口内的整体背景信息（计算平均值）avg_pool = nn.AvgPool2d(kernel_size=2, stride=2)# 执行池化output_max = max_pool(input_data)output_avg = avg_pool(input_data)print(\"--- 原始输入 (4x4) ---\")print(input_data[0,0])print(\"\\n--- 最大池化结果 (2x2) ---\")print(output_max[0,0])print(\"\\n--- 平均池化结果 (2x2) ---\")print(output_avg[0,0])\"\"\"--- 原始输入 (4x4) ---tensor([[ 10., 20., 5., 0.], [ 30., 40., 0., 5.], [ 1., 2., 100., 80.], [ 0., 1., 90., 70.]])--- 最大池化结果 (2x2) ---tensor([[ 40., 5.], [ 2., 100.]])--- 平均池化结果 (2x2) ---tensor([[25.0000, 2.5000], [ 1.0000, 85.0000]])\"\"\" 线性层的使用1234567891011121314151617181920212223242526import torchimport torch.nn as nn# 模拟一个卷积层输出的特征图 (Batch=1, Channel=64, H=4, W=4)input_feature_map = torch.randn(1, 64, 4, 4)# --- 1. Flatten (展平层) ---# 将三维特征 (C, H, W) 转化为一维特征向量。默认从 dim=1 开始展平，保留 dim=0 的 Batch 维度。flatten = nn.Flatten()output_flatten = flatten(input_feature_map)# --- 2. Linear (线性层/全连接层) ---# 每一个输出节点都连接了输入的所有节点，用于学习全局组合逻辑。fc = nn.Linear(in_features=1024, out_features=256)output_fc = fc(output_flatten)# --- 3. Dropout (随机失活层) ---# 强制让网络在训练时不要依赖某些特定的神经元。# p=0.5 表示每次训练时，随机把一半的神经元“关掉”（置为0）。dropout = nn.Dropout(p=0.5)output_dropout = dropout(output_fc)print(f\"输入特征图形状: {input_feature_map.shape}\") # [1, 64, 4, 4]print(f\"展平后形状: {output_flatten.shape}\") # [1, 1024]print(f\"线性层输出形状: {output_fc.shape}\") # [1, 256] 非线性激活的使用123456789101112131415161718192021import torchimport torch.nn as nn# 模拟一个包含正数、负数和零的输入张量input_data = torch.tensor([-2.0, -1.0, 0.0, 1.0, 2.0])# 1. ReLU 激活函数：简单高效# 逻辑：max(0, x)relu = nn.ReLU()# 2. Sigmoid 激活函数：压缩映射sigmoid = nn.Sigmoid()# 执行激活操作output_relu = relu(input_data)output_sigmoid = sigmoid(input_data)print(f\"输入数据: {input_data}\")print(f\"ReLU 输出: {output_relu}\")print(f\"Sigmoid 输出: {output_sigmoid}\") 模型训练反向传播手动实现1234567891011121314151617181920212223242526272829303132333435363738394041424344import torch# 1. 初始化x = torch.tensor([0.5])y = torch.tensor([1.0])w1 = torch.tensor([0.2])w2 = torch.tensor([0.5])learning_rate = 0.1for epoch in range(3): # --- A. 前向传播 --- z1 = w1 * x a1 = torch.sigmoid(z1) z2 = w2 * a1 a2 = torch.sigmoid(z2) C = 0.5 * (a2 - y) ** 2 # --- B. 反向传播 --- # --- 第一步：计算 w2 的梯度 (输出层) --- # 公式：dC/dw2 = (dC/da2) * (da2/dz2) * (dz2/dw2) dC_da2 = a2 - y # Loss 对预测值的导数 da2_dz2 = a2 * (1 - a2) # Sigmoid 导数 dz2_dw2 = a1 # 因为 z2 = w2 * a1，对 w2 求导剩下 a1 grad_w2 = dC_da2 * da2_dz2 * dz2_dw2 # --- 第二步：计算 w1 的梯度 (隐含层) --- # 公式：dC/dw1 = [(dC/da2) * (da2/dz2) * (dz2/da1)] * (dz1/dw1) * (da1/dz1) # 方括号的内容表示半成品a1的改变对总损失C的影响 dz2_da1 = w2 dz1_dw1 = x da1_dz1 = a1 * (1 - a1) # 链式相乘：(dC/da2 * da2/dz2) 即是上一层的误差传递，再乘以 (dz2/da1 * da1/dz1 * dz1/dw1) grad_w1 = dC_da2 * da2_dz2 * dz2_da1 * dz1_dw1 * da1_dz1 # --- C. 权重更新 --- w1 = w1 - learning_rate * grad_w1 w2 = w2 - learning_rate * grad_w2 # 打印查看每轮的变化 print(f\"Epoch {epoch + 1}: Loss = {C.item():.4f}, w1 = {w1.item():.4f}, w2 = {w2.item():.4f}\") 完整训练示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118import torchimport torch.nn as nnfrom torch.utils.data import DataLoader, ConcatDatasetfrom torchvision import transformsfrom PIL import Imageimport os# --- 1. 数据集定义 ---class MyData(torch.utils.data.Dataset): def __init__(self, root_dir, label_dir, transform=None): self.root_dir = root_dir self.label_dir = label_dir self.path = os.path.join(self.root_dir, self.label_dir) self.img_path = os.listdir(self.path) self.transform = transform # ants -&gt; 0, bees -&gt; 1 self.label = 0 if label_dir == \"ants\" else 1 def __getitem__(self, idx): img_name = self.img_path[idx] img_item_path = os.path.join(self.path, img_name) img = Image.open(img_item_path).convert(\"RGB\") # 保证三通道 if self.transform: img = self.transform(img) return img, self.label def __len__(self): return len(self.img_path)# --- 2. 配置变换 ---data_transforms = transforms.Compose( [ transforms.Resize((64, 64)), transforms.ToTensor(), transforms.Normalize([0.5, 0.5, 0.5], [0.2, 0.2, 0.2]), ])# --- 3. 准备加载器 ---train_root = r\"D:\\RecommendationSystem\\PyTorch学习\\hymenoptera_data\\train\"val_root = r\"D:\\RecommendationSystem\\PyTorch学习\\hymenoptera_data\\val\"# 训练集train_ants = MyData(train_root, \"ants\", transform=data_transforms)train_bees = MyData(train_root, \"bees\", transform=data_transforms)train_loader = DataLoader( ConcatDataset([train_ants, train_bees]), batch_size=8, shuffle=True)# 验证集val_ants = MyData(val_root, \"ants\", transform=data_transforms)val_bees = MyData(val_root, \"bees\", transform=data_transforms)val_loader = DataLoader( ConcatDataset([val_ants, val_bees]), batch_size=8, shuffle=False)# --- 4. 模型定义 ---class SimpleCNN(nn.Module): def __init__(self): super().__init__() self.model = nn.Sequential( nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2), nn.Flatten(), nn.Linear(16 * 32 * 32, 2), ) def forward(self, x): return self.model(x)device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")model = SimpleCNN().to(device)loss_fn = nn.CrossEntropyLoss()optimizer = torch.optim.SGD(model.parameters(), lr=0.01)# --- 5. 训练与评估循环 ---for epoch in range(10): # 训练阶段 model.train() # 切换到训练模式 train_loss = 0 for imgs, labels in train_loader: imgs, labels = imgs.to(device), labels.to(device) outputs = model(imgs) loss = loss_fn(outputs, labels) optimizer.zero_grad() loss.backward() optimizer.step() train_loss += loss.item() # 评估阶段 model.eval() # 切换到评估模式 val_loss = 0 total_accuracy = 0 with torch.no_grad(): # 评估时不计算梯度，节省内存和计算量 for imgs, labels in val_loader: imgs, labels = imgs.to(device), labels.to(device) outputs = model(imgs) loss = loss_fn(outputs, labels) val_loss += loss.item() # 计算准确率 predictions = outputs.argmax(1) # 获取概率最大的类别索引 total_accuracy += (predictions == labels).sum().item() avg_acc = total_accuracy / len(val_loader.dataset) print(f\"Epoch {epoch}: Train Loss: {train_loss:.3f}, Val Acc: {avg_acc:.2%}\")# --- 6. 保存模型 ---os.makedirs(\"models\", exist_ok=True)torch.save(model.state_dict(), \"models/best_model.pth\") 损失函数12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import torchimport torch.nn as nn# 设置随机种子保证结果可复现torch.manual_seed(42)# ==========================================# 场景 A：回归问题 (Regression)# 常用 L1Loss 或 MSELoss# ==========================================# 预测值与真实值predict = torch.tensor([1.0, 2.0, 3.0])target = torch.tensor([1.0, 2.0, 5.0])# 1. L1Loss: 计算平均绝对误差 (Mean Absolute Error, MAE)# 公式: sum(|predict - target|) / n = (0 + 0 + 2) / 3 = 0.6667loss_l1 = nn.L1Loss()res_l1 = loss_l1(predict, target)# 2. MSELoss: 计算均方误差 (Mean Squared Error)# 公式: sum((predict - target)^2) / n = (0^2 + 0^2 + 2^2) / 3 = 4 / 3 = 1.3333loss_mse = nn.MSELoss()res_mse = loss_mse(predict, target)print(\"--- 回归损失 (Regression Losses) ---\")print(f\"L1 Loss (MAE): {res_l1.item():.4f}\")print(f\"MSE Loss: {res_mse.item():.4f}\\n\")# ==========================================# 场景 B：分类问题 (Classification)# 常用 CrossEntropyLoss# ==========================================# 假设我们在做一个三分类任务（如：猫、狗、猪）# 输入 x: 模型给出的每个类别的得分 (Logits)，形状为 (样本数, 类别数)# 目标 y: 真实类别的索引 (Index)，形状为 (样本数)x = torch.tensor([[0.1, 0.2, 0.3]]) # 模型预测各类的“信心”y = torch.tensor([1]) # 真实标签是索引 1 (比如“狗”)# CrossEntropyLoss 会自动帮我们做 Softmax + Log + NLLLossloss_ce = nn.CrossEntropyLoss()res_ce = loss_ce(x, y)\"\"\"对网络输出的样本分数使用softmax转换成概率对真实标签下的预测样本取负对数似然，即为损失\"\"\"print(\"--- 分类损失 (Classification Loss) ---\")print(f\"CrossEntropy Loss: {res_ce.item():.4f}\")","categories":[{"name":"算法学习","slug":"算法学习","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"数据挖掘学习笔记：朴素贝叶斯","slug":"数据挖掘学习笔记：朴素贝叶斯","date":"2026-01-04T14:12:08.000Z","updated":"2026-01-13T13:53:11.846Z","comments":true,"path":"2026/01/04/数据挖掘学习笔记：朴素贝叶斯/","permalink":"http://example.com/2026/01/04/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/","excerpt":"本文记录了我对朴素贝叶斯的学习过程，包含算法的推导和代码实现。","text":"本文记录了我对朴素贝叶斯的学习过程，包含算法的推导和代码实现。机器学习系列（四）：朴素贝叶斯（华强买瓜版） - yyxy的文章 - 知乎十分钟，让你再也忘不掉贝叶斯分类 - VoidHaruhi的文章 - 知乎《机器学习》（西瓜书）公式详解【吃瓜教程】《机器学习公式详解》（南瓜书）与西瓜书公式推导到底要如何理解条件概率？ - 石溪的回答 - 知乎如何在 Python 中从零开始实现朴素贝叶斯 数据挖掘学习笔记：朴素贝叶斯贝叶斯决策论假设当前有一个 分类任务，即 ，将 定义为将一个真实标记 的样本误分类为 所产生的损失。如果其目标为最小化分类错误率，则损失 可写为：，，，此时，对于单个样本 而言，定义其期望损失为如下条件风险的形式：上式中， 为后验概率。 那么，贝叶斯决策论的任务就是去寻找一个判定准则 ，以最小化全部样本构成的总体风险：在定义完上述概念之后，我们就可以引入贝叶斯判定准则，即最小化总体风险 。因此，只需在每个样本上选择那个能使条件风险 最小的类别标记：$$h^(\\boldsymbol{x})=\\underset{c\\in \\mathcal{Y}} {\\arg\\min}\\ R(c|\\boldsymbol{x}),\\tag{4}$$此时，$h^$ 被称为贝叶斯最优分类器（Bayes optimal classifier）。 对公式展开得：$$R(c_i|\\boldsymbol{x})=1P(c_1|\\boldsymbol{x})+\\cdots+0P(c_i|\\boldsymbol{x})+1P(c_{i+1}|\\boldsymbol{x})+\\cdots+1P(c_N|\\boldsymbol{x}),\\tag{5}对于一个分类任务而言，所有类别预测的概率总和一定为，即：\\sum_{j=1}^N{P(c_j|\\boldsymbol{x})}=1.\\tag{6}此时，条件风险可化简为：R(c_i|\\boldsymbol{x})=1-P(c_i|\\boldsymbol{x}).\\tag{7}于是，最小化分类错误率的贝叶斯最优分类器可写为：h^*(\\boldsymbol{x})=\\underset{c\\in \\mathcal{Y}}{\\arg\\max}\\ P(c|\\boldsymbol{x}).\\tag{8}$$对每个样本 ，选择能使后验概率 最大的类别标记。 生成式模型与判别式模型如 SVM 这样的机器学习模型，其本质是在特征空间内寻找一个超平面把类别样本划分开，是一个从几何角度思考的模型，并没有涉及概率的计算。所谓判别式模型，就是直接对后验概率进行建模，求出每个类别的概率进行分类。下面要将的朴素贝叶斯则属于生成式模型，其先对联合概率先进行建模，再推导出后验概率，即：公式是很简单的条件概率一般定义，可以从古典概型进行推导。 假定一个试验有 个等可能的结果，事件 和 分别包含 个和 个结果，这其中有 个结果是公共的，这就是同时发生事件 和事件 ，即 事件所包含的试验结果数。 那么已知在事件 发生的前提条件下，事件 发生的概率为： 对于上式，可以进行展开： 故可以得到条件概率的一般定义： ​回到公式，用贝叶斯定理可以恒等变形为：其中， 是先验概率， 是样本 相对于类别标记是类条件概率，也叫似然， 是归一化用的证据因子。 在公式中最难建模的是类条件概率，假如样本 有 个特征，每个特征又有多个取值，那么样本相对于类别 的组合数不胜数，甚至在数据集中都没有这种组合。那如何把这个类条件概率计算出来呢？朴素贝叶斯给了这么一种方法。 朴素贝叶斯朴素贝叶斯假设对于已知类别，各个属性相互独立，即满足属性条件独立性假设。那么后验概率可以写成：其中， 为属性数目， 表示 在第 个属性上的取值。基于贝叶斯判定准则可得：$$h^(x)=\\underset{c\\in \\mathcal{Y}}{\\arg\\max}\\ \\frac{P(c)}{P(\\boldsymbol{x})}\\prod_{i=1}^dP(x_i|c).\\tag{15}$$综上所述，样本所属的哪个类别的后验概率最大，就选择哪个类别作为模型 $h^(x)$ 的预测结果。那么，现在的问题就是，如何计算类条件概率和先验概率，才能使得模型预测得最准，即条件风险最小。 对于先验概率的计算很简单，利用大数定理，在训练集样本足够多的情况下用频率近似概率：其中， 表示训练集 中类别标记为的样本集合， 表示集合 的样本总数。 对于类条件概率的计算要分成两种情况讨论：离散属性和连续属性。对于离散属性的类条件概率计算思路和公式一样，因此第 个属性为离散属性的类条件概率为：其中， 表示 在第个属性上取值为 的样本组成的集合。 然而，如果某个属性值在训练集中没有与某个类别同时出现过，直接使用公式计算，则会让连乘式子结果为 0。为避免出现这种情况，在估计概率值时应该加以平滑，按《西瓜书》的示例，使用拉普拉斯修正：Multiple \\tag \\begin{align} \\hat P(c) &amp;= \\frac{|D_c|+1}{|D|+N}\\tag{18}, \\[4pt] \\hat P(x_i|c) &amp;= \\frac{|D_{c,x_i}|+1}{|D_c|+N_i},\\tag{19} \\end{align} 其中， 表示类别数量， 表示第 个属性出现的取值数量。 对于连续属性，假设满足正态分布，那么其概率密度函数为：其中， 和 分别表示第 类样本在第 个属性上取值的均值和方差。 接下来，我们使用极大似然估计去估计其均值和方差。公式为一元正态分布的概率密度函数，下面对于多元正态分布的概率密度函数 而言，其等价形式为：其中， 表示 的维数， 为正定协方差矩阵。 对数极大似然估计的参数求解形式为：$$\\begin{align}\\hat{\\boldsymbol{\\theta}_c} &amp;= \\underset{\\boldsymbol{\\theta}_c}{\\arg\\max}\\ LL(\\boldsymbol{\\theta}_c) \\[4pt]&amp;= \\underset{\\boldsymbol{\\theta}c}{\\arg\\min}\\ -\\sum{\\boldsymbol{x}\\in D_c}\\log P(\\boldsymbol{x}|\\boldsymbol{\\boldsymbol{\\theta}_c})\\end{align} \\tag{22}通过极大似然估计的均值和方差如下：\\hat {\\boldsymbol{\\mu}}c=\\frac{1}{|D_c|}\\sum{\\boldsymbol{x}\\in D_c}\\boldsymbol{x},\\tag{23}$$ $$\\hat{\\boldsymbol{\\sigma}}c^2=\\frac{1}{|D_c|}\\sum{\\boldsymbol{x}\\in D_c}(\\boldsymbol{x}-\\hat {\\boldsymbol{\\mu}}_c)(\\boldsymbol{x}-\\hat {\\boldsymbol{\\mu}}_c)^T.\\tag{24}$$ 详细的推导过程见南瓜书第 63~64 页。 假如说，将朴素贝叶斯应用于你的数据集上发现效果并不理想，那么可以考虑更换概率分布，这或许可以看作是贝叶斯分类的超参数。当然，也有可能数据集上的各个属性不独立。 实现代码代码中使用的数据集来自和鲸社区：皮马印第安人糖尿病数据库。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687import mathimport pandas as pd# 皮马印第安人糖尿病数据train_data = pd.read_csv(r'train_data.csv').valuestest_data = pd.read_csv(r'test_data.csv').values# 划分连续和离散型变量continuous_columns = [1, 2, 3, 4, 5, 6] # Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunctiondiscrete_columns = [0, 7] # Pregnancies, Age# 将数据按类别分离separated_data = {0: [], 1: []} # 创建一个空字典用来存储两个类别下的样本for row in train_data: class_label = row[-1] # 获取类别列 separated_data[class_label].append(row) # 把相同类别下的样本放到一起# 分别计算两个类别下每个连续变量的均值和标准差、和离散变量的频率class_summaries = {} # 创建一个空字典用来存储两个类别下连续变量和离散变量的统计信息for class_label, rows in separated_data.items(): summaries = {} # 连续型变量的均值和标准差 continuous_summaries = [] for col_idx in continuous_columns: column = [row[col_idx] for row in rows] # 把连续变量的一整列提取出来 mean_val = sum(column) / len(column) # 计算均值 μ_c variance = sum([(x - mean_val) ** 2 for x in column]) / len(column) # 计算方差 σ_c^2 stdev_val = math.sqrt(variance) # 计算标准差 σ_c continuous_summaries.append((mean_val, stdev_val)) # 离散型变量的频率计算 discrete_summaries = [] for col_idx in discrete_columns: column = [row[col_idx] for row in rows] # 把离散变量的一整列提取出来 value_counts = {val: column.count(val) for val in set(column)} # 统计离散变量中每个取值出现的个数，加1是拉普拉斯修正 total_count = len(rows) discrete_summaries.append((value_counts, total_count)) # 存储两个类别下连续型和离散型的特征统计信息 summaries['continuous'] = continuous_summaries summaries['discrete'] = discrete_summaries class_summaries[class_label] = summaries# 拉普拉斯修正后的先验概率class_prior = {}total_samples = len(train_data) # 样本长度 |D|num_classes = len(class_summaries) # 类别数 Nfor class_label in separated_data: # 取出两个类别的样本 class_count = len(separated_data[class_label]) # 两个类别各自的样本数量 |D_c| class_prior[class_label] = (class_count + 1) / (total_samples + num_classes)# 分类predictions = []for row in test_data: # 对测试集的每一个样本进行分类 probabilities = {} for class_label, summaries in class_summaries.items(): # 两个类别下连续变量和离散变量的统计信息 # 将第一个类条件概率初始化为先验概率 probabilities[class_label] = class_prior[class_label] # 连续变量的类条件概率 for i, (mean_val, stdev_val) in enumerate(summaries['continuous']): x = row[continuous_columns[i]] # 测试集每个样本中每个连续变量的取值 exponent = math.exp(-((x - mean_val) ** 2 / (2 * stdev_val ** 2))) continous_probability = (1 / (math.sqrt(2 * math.pi) * stdev_val)) * exponent probabilities[class_label] *= continous_probability # 离散变量的类条件概率 for i, (value_counts, total_count) in enumerate(summaries['discrete']): x = row[discrete_columns[i]] num_values = len(value_counts) # 变量取值的数量 N_i discrete_probability = (value_counts.get(x, 0) + 1) / (total_count + num_values) # 拉普拉斯修正 probabilities[class_label] *= discrete_probability # 计算归一化因子 P(x) total_probability = sum(probabilities.values()) for class_label in probabilities: probabilities[class_label] /= total_probability best_class = max(probabilities, key=probabilities.get) # 看看哪个类别的后验概率大 predictions.append(best_class)# 计算准确率correct_predictions = sum(1 for i in range(len(test_data)) if test_data[i][-1] == predictions[i])accuracy = (correct_predictions / len(test_data)) * 100.0print(f'code_accuracy: {accuracy:.4f}%') 半朴素贝叶斯朴素贝叶斯是基于各属性都相互独立的假设进行的，但现实生活中并没有如此理想。半朴素贝叶斯则适当考虑一部分属性间的相互依赖信息，从而既不需进行完全联合概率计算，又不至于彻底忽略了比较强的属性依赖关系。 回顾公式，朴素贝叶斯的类条件概率考虑的是只与一个属性 有关，而半朴素贝叶斯不仅考虑属性 ，还考虑其他的一个属性，即独依赖估计（ODE）：其中， 表示属性 所依赖的属性，称为 的父属性。 对于如何确定父属性，最直接的做法是假设所有属性都依赖于同一个属性，即超父独依赖估计（SPODE）：其中， 为超父属性。","categories":[{"name":"算法学习","slug":"算法学习","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"《Optimal Discriminant Support Vector Machine》阅读笔记","slug":"Optimal-Discriminant-Support-Vector-Machine阅读笔记","date":"2026-01-04T11:58:29.000Z","updated":"2026-01-04T16:03:05.772Z","comments":true,"path":"2026/01/04/Optimal-Discriminant-Support-Vector-Machine阅读笔记/","permalink":"http://example.com/2026/01/04/Optimal-Discriminant-Support-Vector-Machine%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/","excerpt":"本文是对《Optimal Discriminant Support Vector Machine》这篇文章的阅读笔记，推导了二分类情景下文章所提模型目标函数的设计和求解过程。","text":"本文是对《Optimal Discriminant Support Vector Machine》这篇文章的阅读笔记，推导了二分类情景下文章所提模型目标函数的设计和求解过程。Zhang, J., Lai, Z., Kong, H., &amp; Yang, J. (2025). Learning the optimal discriminant SVM with feature extraction. IEEE Transactions on Pattern Analysis and Machine Intelligence, 47(4), 2897–2911. https://doi.org/10.1109/TPAMI.2025.3529711. 模型总览ODSVM 将子空间学习和 SVM 分类放在一个统一的数学框架内共同进化。 投影矩阵：数据的特征提取器 是一个大小为 的矩阵（ 是原始高维特征维度， 是降维后的维度）。它的作用是将原始样本 投影到低维子空间： 的目标在于丢弃大部分冗余信息的同时，精准地保留最有利于分类的信息。在 ODSVM 中， 的构建受到 SVM 边距最大化的约束。这意味着 提取出的特征 必须让 SVM 能够更容易地找到一个宽阔的分类间隔（Margin）。 重构矩阵：数据的结构保持器 同样是一个 的矩阵，用于衡量投影后的低维特征 是否还保留了原始数据 的核心结构。数学上表现为最小化重构误差：。 如果只追求分类准确率（只优化 和 SVM 参数），模型可能会陷入过拟合，或者提取出极其扭曲的特征。 的存在就像是一条绳子，拉住 ，要求提取的特征不仅要能分得开类别，还得能代表原本的数据。 迭代优化在 ODSVM 的目标函数中，SVM 的参数（）、投影矩阵 和重构矩阵 是紧密耦合在一起的。由于无法直接求出所有变量的最优解，因此论文采用交替迭代优化（Alternating Optimization）的策略。 第一步：固定 和 ，优化 SVM，找最强判别平面 此时， 已经把数据变成了低维特征 。模型退化成一个标准的 SVM 问题。当前的子空间里，找到能把不同类别分得最开的超平面 。 第二步：固定 SVM 参数和 ，优化 需要同时满足两个要求：SVM 要求投影 得让它的分类间隔更大， 要求投影 要能配合重构矩阵更好地还原回 。在这种约束下， 会被微调，使得投影后的数据点在保持结构的同时，向着更有利于分类的方向偏移。 第三步：固定 和 SVM，优化 由于 已经变了，原来的恢复方案 可能不再准确。这一步更新 ，使得它能根据新的低维特征 更好地重建原始数据。 图正则化重构ODSVM 并不是直接最小化低维点的距离，而是通过最小化邻居编码误差（Neighbor-encoding）来间接抑制低维空间中邻居间的距离。 构建有监督图在进入迭代优化前，模型先为所有训练样本构建一个图 ，利用了类别信息和欧氏距离： 同类近邻： 如果样本 和 属于同一类，且 是 的 个最近邻之一，那么就在它们之间连一条边，并赋予一个权重 。 异类或远邻： 如果类别不同或者距离太远，权重 。 邻域编码在构建子空间（学习 和 ）时，目标函数不再仅仅是最小化 ，而是加入了基于图的约束。如果 很大，模型会强制要求： 在低维空间 中靠得更近： 和 的距离必须尽可能小。 共享重构特征： 它们的重构过程应该具有一致性。 对于投影矩阵 要求局部紧致性（Local Compactness）。 在寻找投影方向时，会被要求最小化同类邻居在子空间中的方差。如果 选的方向让原本在一起的同类样本分开了，那么图正则化项就会产生很高的“惩罚值”。因此， 提取出的特征能够保持数据的局部流形结构，即在原始高维空间里邻近的同类点，在低维子空间依然是邻居。 对于重构矩阵 要求结构一致性。 不仅仅是一个数学上的逆变换，它被赋予了“平滑”数据的任务。通过考虑邻域， 学习到的是该类别数据在子空间中的分布规律，而不仅仅是单个点的坐标映射。因此，如果某个样本 含有噪声，但它的邻居们是干净的，邻域编码会利用邻居的结构信息来辅助 的重构，从而“纠正”噪声样本在子空间中的偏离。 优化过程以二分类为例，定义目标函数：$$\\min_{w, P, Q} \\mathcal{J} = \\underbrace{\\frac{1}{2}|w|2^2 + c \\sum{i=1}^n [1 - y_i w^\\top P^\\top x_i]+}{\\text{SVM 分类项}} + \\underbrace{\\frac{\\lambda}{2} \\sum_{i,j=1}^n |x_i - Q P^\\top x_j|2^2 G{ij}}_{\\text{图正则化重构项}} + \\underbrace{\\frac{\\gamma}{2}|P|F^2}{\\text{正则化项}}$$约束条件为：。 其中， 是投影矩阵， 是重构字典， 是低维空间中的分类权重， 是刻画局部结构的图权重矩阵。 用于平衡“最大化分类间隔”和“最小化分类错误”之间的权重， 越大，对分类错误的容忍度越低。 用于控制“特征提取/结构保持”这一项在总目标函数中的重要性， 越大，模型越强调整体数据的结构保持和类内紧凑性。 用于控制投影矩阵的复杂度。 是取正值的意思，在 SVM 中用来定义 Hinge Loss，若分对了且离边界够远，就不产生 Loss。分类错误或分类正确但离边界太近，损失就为正数，离正确边界越远，惩罚越大，迫使模型去修正参数。 $\\frac{1}{2}|w|2^2 + c \\sum [1 - y_i w^\\top P^\\top x_i]+是标准的损失函数，但输入数据变成了P^\\top x_i，这意味着模型在寻找P和w$ 使得数据在投影后能被最大间隔分开（最大化类间间隔）。 $\\frac{\\lambda}{2} \\sum |x_i - Q P^\\top x_j|2^2 G{ij}这一项利用邻居x_j的投影P^\\top x_j，通过Q映射回来去重构x_i$，同类样本在低维空间应该靠得很近，并且能保留原始数据的信息。这起到了“最小化类内散度”的作用。 是正则化项，防止投影矩阵 的值过大。 第一阶段：固定投影矩阵和重构字典，优化 SVM当 和 固定时，目标函数中与 相关的重构项和正则项都变成了常数。此时问题退化为：$$\\min_{w} \\frac{1}{2}|w|2^2 + c \\sum{i=1}^n [1 - y_i w^\\top (P^\\top x_i)]_+$$这就是一个标准的线性 SVM 训练问题。目标是在投影后的低维子空间内，找到一个超平面系数 ，使得分类间隔（Margin）最大化。 第二阶段：固定 SVM 参数和重构字典，优化投影矩阵因为 同时存在于分类项和重构项中。为了求解，作者引入松弛变量 并利用对偶理论。 首先进行目标函数重构，利用矩阵迹（Trace）的性质，重构项可以转化为：$$\\sum_{i,j=1}^n |x_i - Q P^\\top x_j|2^2 G{ij} = Tr(P^\\top S_A P) - 2 Tr(P^\\top S_B Q) + \\text{const}其中和，这两个矩阵被称为散射矩阵（）。通常与数据的全局能量或总方差有关，而捕获了基于图结构的局部相关性。是度矩阵（），是一个对角矩阵，其对角线上的元素是矩阵第行（或列）元素的总和：D_{ii} = \\sum_{j=1}^n G_{ij}$$在矩阵运算中，迹 是矩阵对角线元素之和。 向量或矩阵的二范数平方可以写成迹的形式：。对于矩阵 ：。 矩阵的迹还有循环移位的性质：。如果一个运算的结果是标量，那么它的迹等于它本身：。 推导过程首先利用向量范数公式 $|a - b|2^2 = a^\\top a - 2 a^\\top b + b^\\top b，将目标函数展开为三项：$L = \\sum{i,j=1}^n \\left( \\underbrace{x_i^\\top x_i}{\\text{第一项}} - \\underbrace{2 x_i^\\top (Q P^\\top x_j)}{\\text{第二项}} + \\underbrace{(Q P^\\top x_j)^\\top (Q P^\\top x_j)}{\\text{第三项}} \\right) G{ij}第一项是常数项，由于和在优化阶段都是已知的，这一项不包含变量和，因此记为：\\sum_{i,j=1}^n x_i^\\top x_i G_{ij} = \\sum_{i=1}^n |x_i|2^2 \\left( \\sum{j=1}^n G_{ij} \\right) = \\sum_{i=1}^n |x_i|2^2 D{ii}在第二项中，由于是一个标量，它等于自身的迹：-2 \\sum_{i,j=1}^n G_{ij} Tr(x_i^\\top Q P^\\top x_j)利用迹的循环性质，将移到前面：-2 \\sum_{i,j=1}^n Tr(P^\\top x_j G_{ij} x_i^\\top Q)由于迹运算对求和是线性的，提取和：-2 Tr \\left( P^\\top \\left( \\sum_{i,j=1}^n x_j G_{ij} x_i^\\top \\right) Q \\right)由于正好是矩阵乘法的展开形式，定义，则该项为：-2 Tr(P^\\top S_B Q)第三项首先利用正交约束简化内部项：(Q P^\\top x_j)^\\top (Q P^\\top x_j) = x_j^\\top P \\underbrace{Q^\\top Q}_{I} P^\\top x_j = x_j^\\top P P^\\top x_j$$ 的作用是将低维特征 “还原”回原始空间。如果没有 这个约束，模型可以通过无限缩小 并无限放大 来保持乘积不变。这会导致计算极其不稳定。正交基意味着模型是在一个标准直角坐标系下进行重构，这保证了重构过程只是在寻找原始数据在子空间上的投影点，而不会对数据产生非线性的拉伸或剪切。 对于投影矩阵而言， 的角色是寻找最有利于分类的特征，虽然 没有正交约束，但它有 $|P|F^2正则化项。这里的正则化是范数，把矩阵里所有的元素先平方、再求和、最后开根号。范数限制了投影矩阵P中元素的大小。如果没有这一项，P的数值可能会为了迎合某些噪声数据而变得极大，导致模型泛化能力变差：$|P|F = \\sqrt{\\sum{i=1}^m \\sum{j=1}^n p_{ij}^2}回到公式的推导，代回原式并考虑对的求和：\\sum_{i,j=1}^n (x_j^\\top P P^\\top x_j) G_{ij} = \\sum_{j=1}^n (x_j^\\top P P^\\top x_j) \\left( \\sum_{i=1}^n G_{ij} \\right)利用度矩阵定义：\\sum_{j=1}^n D_{jj} (x_j^\\top P P^\\top x_j)转化为迹的形式并利用循环性质：\\sum_{j=1}^n D_{jj} Tr(x_j^\\top P P^\\top x_j) = Tr \\left( P^\\top \\left( \\sum_{j=1}^n D_{jj} x_j x_j^\\top \\right) P \\right)由于正好是矩阵乘法的对角加权形式，定义，则该项为：Tr(P^\\top S_A P)将三项合并，得到了论文中的简洁形式：\\sum_{i,j=1}^n |x_i - Q P^\\top x_j|2^2 G{ij} = Tr(P^\\top S_A P) - 2 Tr(P^\\top S_B Q) + \\text{const}在固定和后，的目标函数与变量和松弛变量相关的部分可以写成：\\min_{P, \\xi} \\mathcal{J}(P, \\xi) = \\underbrace{\\frac{\\lambda}{2} Tr(P^\\top S_A P - 2 P^\\top S_B Q)}{\\text{重构项}} + \\underbrace{\\frac{\\gamma}{2}|P|F^2}{\\text{P 的正则项}} + \\underbrace{c \\sum{i=1}^n \\xi_i}_{\\text{SVM 误差项}}$$约束条件来自于 SVM 的基本要求，即样本必须落在间隔之外或通过松弛变量补偿：，松弛变量非负：。 拉格朗日乘数法要求约束条件写成 的形式：，。 拉格朗日函数的基本构造公式为：目标函数乘子约束。 引入两组拉格朗日乘子： 对应分类约束， 对应非负约束：$$\\begin{aligned}L(P, \\xi, \\alpha, \\beta) &amp;= \\frac{\\lambda}{2} Tr(P^\\top S_A P - 2 P^\\top S_B Q) + \\frac{\\gamma}{2}|P|F^2 + c \\sum{i=1}^n \\xi_i \\&amp;\\quad + \\sum_{i=1}^n \\alpha_i (1 - \\xi_i - y_i w^\\top P^\\top x_i) \\&amp;\\quad + \\sum_{i=1}^n \\beta_i (-\\xi_i)\\end{aligned}进一步把上式进行化简：L(P, \\xi, \\alpha, \\beta) = \\frac{\\lambda}{2} Tr(P^\\top S_A P - 2 P^\\top S_B Q) + \\frac{\\gamma}{2}|P|_F^2 + c e^\\top \\xi + \\sum \\alpha_i (1 - \\xi_i - y_i w^\\top P^\\top x_i)是对分类错误的惩罚总和，其中，所以。这里省略了项，是因为后续的求偏导过程有：\\frac{\\partial L}{\\partial \\xi_i} = c - \\alpha_i - \\beta_i = 0 \\implies \\alpha_i + \\beta_i = c$$由于 ，这个条件隐含了 。因此，针对 优化拉格朗日函数时通常可以省略 项，通过在后续求解 的对偶问题时，给 加上上限 （即 ）来等价地处理 的约束。 接着求导得出 的显式表达，令 ，可以解出 关于 的函数。 首先，从完整的拉格朗日函数中，剔除掉所有不包含 的项，因为求导后会变成0，得到关于 的子函数 ：$$L_P = \\underbrace{\\frac{\\lambda}{2} Tr(P^\\top S_A P)}{\\text{项 1}} - \\underbrace{\\lambda Tr(P^\\top S_B Q)}{\\text{项 2}} + \\underbrace{\\frac{\\gamma}{2} Tr(P^\\top P)}{\\text{项 3}} - \\underbrace{\\sum{i=1}^n \\alpha_i y_i w^\\top P^\\top x_i}_{\\text{项 4}}$$在推导过程需要用到以下三个矩阵求导公式： 公式 A： 。由于 是对称矩阵，结果为 。 公式 B： 。 公式 C： 。 将 分成四部分进行计算： 求导项 1： 根据公式 A，由于 是对称的：项求导项 2： 根据公式 B，其中 ：项求导项 3： 这等价于公式 A 中 的情况：项求导项 4： 这一步需要先进行矩阵化处理。 观察单个项：。这里 是分类权重， 是样本。 利用公式 C，其中 ， 。其导数为 。 对所有 求和：项引入矩阵 和向量 ，上面的求和项 正好等于矩阵乘积 。所以有：项 将上述所有结果合并，得到总梯度：化简后得到：这里包含三部分： 要求投影矩阵配合重构字典 和图结构 ，尽量保留数据的原始几何信息 要求投影矩阵参考 SVM 的分类结果，把不同类别的样本拉开，其通过拉格朗日乘子 和权重 传递 则起到了一个“归一化”和“稳定器”的作用，确保 不会因为单方面的力量而数值爆炸 当得到了上述投影矩阵的显示表达后，接下来要求解针对 的二次规划问题（QPP），需要将第二阶段求得的 的显式表达代回拉格朗日函数中，这个过程被称为对偶化（Dualization）。 首先对拉格朗日函数进行简化：上式合并了重构项和 的正则项，使用 ，以及将分类约束项 写成了矩阵形式：。 利用 Karush-Kuhn-Tucker（KKT） 条件简化 和约束，先针对松弛变量 求偏导：因为乘子 ，这直接给出了 的范围约束：同时，由于 ，拉格朗日函数中的 项变为 0。 把在上一阶段求得 的最优解化简为：其中 。 将 代入拉格朗日函数中关于 的部分：由于 是对称矩阵，因此 也是对称矩阵，有 ，简化得：将 代入：展开后得到四项： 第一项： 。这不包含 ，在优化时是常数。 第二项： 。 第三项： 。 第四项： 。 接下来对上述四项分别求迹，因为第二项和第三项互为转置，因此：对于第四项利用 ，得到：回到一开始的拉格朗日函数：刚刚的化简和求迹都是针对 进行的， 被放在了一边，现在计算完成后需要将结果和 合并：$$\\begin{align*}D(\\alpha) &amp;= -\\frac{1}{2} \\left( |w|_2^2 \\alpha^\\top Z^\\top M Z \\alpha + 2 \\lambda (Z^\\top M S_B Q w)^\\top \\alpha + \\text{const} \\right) + e^\\top \\alpha\\[4pt]&amp;= -\\frac{|w|2^2}{2} \\alpha^\\top (Z^\\top M Z) \\alpha + (e - \\lambda Z^\\top M S_B Q w)^\\top \\alpha + \\text{const}\\end{align*}最大化这个对偶函数，即得到了论文中的问题：\\max{\\alpha} -\\frac{|w|_2^2}{2} \\alpha^\\top Z^\\top M Z \\alpha + (e - \\lambda Z^\\top M S_B Q w)^\\top \\alpha, \\quad \\text{s.t. } 0 \\leq \\alpha_i \\leq c$$这里的二次项 反映了样本在经过 缩放处理后的相关性， 的存在说明分类器的权重直接影响了子空间的拉伸。一次项 表示标准 SVM 要求样本离开超平面，而减去的 部分则是来自重构误差的修正。它告诉模型，如果某个样本为了重构而必须待在某个位置，那么 SVM 对它的分类约束可以稍微“妥协”一点。 第三阶段：固定投影矩阵和 SVM，优化重构字典当 和 固定时，目标函数只剩下与重构相关的部分。 这里把最开始目标函数的简洁形式搬过来：$$\\sum_{i,j=1}^n |x_i - Q P^\\top x_j|2^2 G{ij} = Tr(P^\\top S_A P) - 2 Tr(P^\\top S_B Q) + \\text{const}在这一阶段要优化的重构形式为：\\max_{Q} Tr(P^\\top S_B Q), \\quad \\text{s.t. } Q^\\top Q = I$$这是一个经典的正交普鲁克分析（Orthogonal Procrustes Problem），它有闭式解（Closed-form solution）： 首先计算矩阵乘积 ，对该结果进行奇异值分解（SVD）：，得到的最优的重构矩阵为：。","categories":[{"name":"文献阅读","slug":"文献阅读","permalink":"http://example.com/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"集成学习","slug":"集成学习","permalink":"http://example.com/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"},{"name":"子空间学习","slug":"子空间学习","permalink":"http://example.com/tags/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0/"}]}],"categories":[{"name":"算法学习","slug":"算法学习","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/"},{"name":"文献阅读","slug":"文献阅读","permalink":"http://example.com/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"集成学习","slug":"集成学习","permalink":"http://example.com/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"},{"name":"子空间学习","slug":"子空间学习","permalink":"http://example.com/tags/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0/"}]}